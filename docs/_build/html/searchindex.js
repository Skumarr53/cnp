Search.setIndex({"docnames": ["index", "source/common_utils", "source/data_access", "source/data_processing", "source/embedding", "source/nli_utils", "source/preprocessing", "source/text_processing", "source/utils"], "filenames": ["index.rst", "source/common_utils.rst", "source/data_access.rst", "source/data_processing.rst", "source/embedding.rst", "source/nli_utils.rst", "source/preprocessing.rst", "source/text_processing.rst", "source/utils.rst"], "titles": ["Welcome to Centralized NLP Package\u2019s documentation!", "Common Utils", "Data Access", "Data Processing", "Embedding", "NLI utilities", "Preprocessing", "Text processing", "Utilities"], "terms": {"data": [0, 1, 5], "access": 0, "execute_truncate_or_merge_queri": [0, 2], "get_snowflake_connection_opt": [0, 2], "read_from_snowflak": [0, 2], "retrieve_snowflake_private_kei": [0, 2], "singleton": [0, 2], "with_spark_sess": [0, 2], "write_dataframe_to_snowflak": [0, 2], "embed": 0, "average_token_embed": [0, 4], "save_word2vec_model": [0, 4], "train_word2vec_model": [0, 4], "preprocess": [0, 5], "text": [0, 1, 3], "process": [0, 2, 5], "util": [0, 2], "determine_environ": [0, 8], "common": 0, "format_d": [0, 1], "get_date_rang": [0, 1], "load_content_from_txt": [0, 1], "format_string_templ": [0, 1], "query_constructor": [0, 1], "check_pd_dataframe_for_record": [0, 3], "concatenate_and_reset_index": [0, 3], "df_apply_transform": [0, 3], "df_remove_rows_with_keyword": [0, 3], "save_report": [0, 3], "dask_compute_with_progress": [0, 3], "initialize_dask_cli": [0, 3], "check_spark_dataframe_for_record": [0, 3], "convert_columns_to_timestamp": [0, 3], "create_spark_udf": [0, 3], "define_structur": [0, 3], "equivalent_typ": [0, 3], "get_default_dtype_map": [0, 3], "initialize_spark_sess": [0, 3], "keyword_to_datatyp": [0, 3], "pandas_to_spark": [0, 3], "sparkdf_apply_transform": [0, 3], "nli": 0, "prepare_dataset": [0, 5], "preprocess_dataset": [0, 5], "get_compute_metr": [0, 5], "evalu": [0, 5], "initialize_train": [0, 5], "predict": [0, 5], "setup_log": [0, 5], "train": [0, 4, 5], "main": [0, 5], "run_glu": [0, 5], "index": [0, 3], "modul": 0, "search": 0, "page": 0, "centralized_nlp_packag": [1, 2, 3, 4, 5, 8], "common_util": 1, "date_util": 1, "date": [1, 3], "sourc": [1, 2, 3, 4, 5, 8], "format": [1, 2, 3, 4], "datetim": [1, 3], "object": [1, 3], "string": [1, 3], "yyyi": [1, 3], "mm": [1, 3], "dd": [1, 3], "paramet": [1, 2, 3, 4, 5, 8], "The": [1, 2, 3, 4, 5, 8], "return": [1, 2, 3, 4, 5, 8], "type": [1, 2, 3, 4, 5, 8], "str": [1, 2, 3, 4, 5, 8], "exampl": [1, 2, 3, 4, 5], "from": [1, 2, 3, 4, 5], "import": [1, 2, 3, 4, 5], "2023": [1, 3], "9": [1, 3, 5], "15": [1, 4], "09": 1, "years_back": 1, "0": [1, 3, 4, 5], "months_back": 1, "calcul": 1, "rang": 1, "base": [1, 3, 5, 8], "current": 1, "minu": 1, "specifi": [1, 2, 3, 4, 8], "year": 1, "month": 1, "int": [1, 3], "option": [1, 2, 3, 4, 5, 8], "number": [1, 3], "go": 1, "back": 1, "default": [1, 2, 3, 4], "A": [1, 2, 3, 4, 5], "tupl": [1, 3], "contain": [1, 2, 3], "start": 1, "end": 1, "start_dat": 1, "end_dat": 1, "1": [1, 3, 4, 5], "2": [1, 3, 5], "exmapl": 1, "i": [1, 2, 3, 5], "10": [1, 3, 4], "01": [1, 3, 5], "print": [1, 3, 4], "2022": 1, "08": 1, "file_util": 1, "file_path": 1, "read": 1, "entir": 1, "content": 1, "file": [1, 3, 4], "given": [1, 2, 3], "path": [1, 3, 4, 5], "rais": [1, 2, 3, 8], "filesnotloadedexcept": 1, "If": [1, 2, 3, 8], "found": [1, 3], "sampl": [1, 3], "txt": 1, "thi": [1, 2, 3, 4], "string_util": 1, "templat": 1, "kwarg": [1, 4], "construct": [1, 2], "replac": 1, "placehold": 1, "provid": [1, 2, 3, 4, 5, 8], "keyword": [1, 3, 4], "argument": [1, 3, 4, 5, 8], "form": 1, "kei": [1, 2, 3], "variabl": 1, "valueerror": [1, 3, 8], "ani": [1, 3, 4], "doe": [1, 3], "have": 1, "correspond": [1, 3], "hello": [1, 3, 4], "name": [1, 2, 3, 5, 8], "todai": 1, "dai": 1, "alic": [1, 3], "mondai": 1, "query_input": 1, "queri": [1, 2], "load": [1, 5], "us": [1, 2, 3, 4, 5, 8], "union": [1, 3], "o": [1, 3], "pathlik": 1, "itself": 1, "substitut": 1, "do": 1, "match": 1, "exist": [1, 2, 3, 4], "select": [1, 2], "user": [1, 2, 3, 8], "where": [1, 2, 3], "signup_d": 1, "AND": 1, "12": [1, 3], "31": 1, "data_access": [2, 3], "snowflake_util": 2, "databas": 2, "schema": [2, 3], "execut": [2, 5], "truncat": [2, 3], "merg": 2, "sql": [2, 3], "snowflak": 2, "function": [2, 3, 4, 5], "run": [2, 5], "either": [2, 4], "against": 2, "establish": 2, "spark": [2, 3], "session": [2, 3], "It": 2, "ensur": [2, 4], "within": 2, "correct": 2, "context": 2, "typic": 2, "statement": 2, "target": 2, "confirm": 2, "messag": [2, 3], "indic": 2, "success": 2, "complet": 2, "oper": [2, 3], "except": [2, 3], "an": [2, 3, 4, 5], "error": 2, "tabl": 2, "analytics_db": 2, "public": 2, "sales_data": 2, "eds_prod": 2, "quant": 2, "env": 2, "none": [2, 3, 4, 5, 8], "dictionari": [2, 3], "connect": 2, "includ": 2, "account": 2, "url": 2, "credenti": 2, "privat": 2, "timezon": 2, "role": 2, "dict": [2, 3, 5], "snowflake_opt": 2, "result": [2, 3], "datafram": [2, 3], "set": [2, 3], "appropri": 2, "df": [2, 3], "show": [2, 3], "config": 2, "retriev": 2, "azur": 2, "vault": 2, "akv": 2, "fetch": 2, "encrypt": 2, "password": 2, "decrypt": 2, "authent": 2, "pem": 2, "suitabl": 2, "private_kei": 2, "cl": 2, "decor": 2, "make": 2, "class": 2, "onli": 2, "one": [2, 3], "instanc": [2, 3, 5], "func": [2, 3], "initi": [2, 3, 4, 5], "befor": 2, "table_nam": 2, "mode": 2, "append": 2, "write": 2, "allow": 2, "correctli": 2, "direct": 2, "intend": 2, "locat": 2, "written": 2, "behavior": 2, "alreadi": 2, "ar": [2, 3, 4], "overwrit": [2, 3], "new": [2, 3], "throw": 2, "ignor": 2, "data_process": 3, "dataframe_util": 3, "datetime_col": 3, "parsed_datetime_eastern_tz": 3, "exit_on_empti": 3, "true": [3, 5], "exit_method": 3, "both": 3, "check": 3, "non": 3, "empti": 3, "relev": 3, "inform": 3, "exit": 3, "program": 3, "pd": 3, "column": 3, "determin": [3, 8], "span": 3, "bool": [3, 4, 5], "whether": [3, 4, 5], "method": 3, "dbutil": 3, "drop_column": 3, "concaten": 3, "multipl": 3, "panda": 3, "reset": 3, "drop": 3, "old": 3, "perform": 3, "follow": 3, "step": 3, "along": 3, "row": 3, "list": [3, 4], "after": 3, "input": 3, "keyerror": 3, "rdf": 3, "b": 3, "3": [3, 5], "4": 3, "cdf": 3, "5": [3, 4, 5], "6": 3, "7": 3, "8": [3, 5], "sdf": 3, "11": 3, "concatdf": 3, "transform": [3, 5], "appli": 3, "each": 3, "should": 3, "new_column": 3, "creat": 3, "columns_to_us": 3, "": [3, 4], "callabl": [3, 5], "invalid": 3, "re": 3, "occur": 3, "dure": 3, "log": [3, 5], "def": 3, "concat_column": 3, "f": 3, "_": 3, "col1": 3, "col2": 3, "c": 3, "d": 3, "col3": 3, "lambda": 3, "transformed_df": 3, "a_c": 3, "b_d": 3, "column_nam": 3, "filter": 3, "remov": 3, "out": 3, "comment": 3, "good": 3, "product": 3, "bad": 3, "servic": 3, "averag": [3, 4], "experi": 3, "filtered_df": 3, "save": [3, 4], "report": 3, "csv": [3, 5], "parquet": 3, "extens": 3, "infer": 3, "support": 3, "importerror": 3, "requir": 3, "engin": 3, "instal": 3, "usag": [3, 5], "save_report_modul": 3, "assum": 3, "py": 3, "bob": 3, "charli": 3, "score": 3, "85": 3, "92": 3, "78": 3, "dask_util": 3, "dask_datafram": 3, "use_progress": 3, "comput": [3, 5], "dask": 3, "displai": 3, "progress": 3, "bar": 3, "e": [3, 4], "g": [3, 4], "read_csv": 3, "computed_df": 3, "head": 3, "column1": 3, "column2": 3, "n_worker": 3, "32": 3, "threads_per_work": 3, "client": 3, "worker": [3, 4], "thread": 3, "per": 3, "distribut": 3, "0x": 3, "spark_util": 3, "spark_df": 3, "record": 3, "present": 3, "minimum": 3, "maximum": 3, "pars": 3, "count": 3, "warn": 3, "notebook": 3, "valid": [3, 5], "columns_format": 3, "convert": 3, "timestamp": 3, "iter": 3, "over": 3, "to_timestamp": 3, "valu": 3, "rubric": 3, "report_d": 3, "hh": 3, "ss": 3, "event_datetime_utc": 3, "fals": [3, 4, 5], "suffix": 3, "_t": 3, "pyspark": 3, "sparksess": 3, "builder": 3, "appnam": 3, "exampleapp": 3, "getorcr": 3, "00": 3, "02": 3, "13": 3, "30": 3, "45": 3, "createdatafram": 3, "columns_to_convert": 3, "converted_df": 3, "printschema": 3, "root": 3, "nullabl": 3, "return_type_kei": 3, "arr": 3, "defin": 3, "udf": 3, "python": 3, "arrai": [3, 4, 5], "userdefinedfunct": 3, "creation": 3, "fail": 3, "other": 3, "reason": 3, "pandas_dtyp": 3, "column_map": 3, "structfield": 3, "structtyp": 3, "dtype": [3, 4], "map": 3, "identifi": 3, "datatyp": 3, "prioriti": 3, "app_nam": 3, "optimized_nli_infer": 3, "shuffle_partit": 3, "200": 3, "gpu_amount": 3, "task_gpu_amount": 3, "executor_memori": 3, "4g": 3, "driver_memori": 3, "2g": 3, "executor_cor": 3, "memory_overhead": 3, "512m": 3, "dynamic_alloc": 3, "configur": [3, 4, 5], "applic": 3, "partit": 3, "shuffl": 3, "float": 3, "amount": 3, "gpu": 3, "resourc": 3, "alloc": 3, "executor": 3, "task": [3, 5], "memori": 3, "driver": 3, "core": 3, "overhead": 3, "enabl": 3, "dynam": 3, "pandas_df": 3, "column_type_map": 3, "customiz": 3, "its": 3, "predefin": 3, "stringtyp": 3, "int64": 3, "longtyp": 3, "int32": 3, "integertyp": 3, "float64": 3, "doubletyp": 3, "float32": [3, 4], "floattyp": 3, "booleantyp": 3, "datetime64": 3, "n": 3, "timestamptyp": 3, "timedelta": 3, "activ": 3, "filt_md": 3, "arr_str": 3, "stat": 3, "map_str_int": 3, "custom": 3, "arraytyp": 3, "long": 3, "doubl": 3, "maptyp": 3, "issu": 3, "convers": 3, "error_on_miss": 3, "seri": 3, "specif": 3, "overwritten": 3, "new_column_nam": 3, "input_column": 3, "transformation_funct": 3, "pass": 3, "take": 3, "more": 3, "miss": 3, "skip": 3, "all": 3, "typeerror": 3, "structur": 3, "transformationexampl": 3, "world": [3, 4], "text_column": 3, "date_column": 3, "to_upp": 3, "upper": 3, "els": 3, "extract_year": 3, "date_str": 3, "split": 3, "to_upper_udf": 3, "extract_year_udf": 3, "text_upp": 3, "year_extract": 3, "combin": 3, "concat": 3, "lit": 3, "apply_transform": 3, "output": [3, 5], "embedding_util": 4, "token": [4, 5], "model": [4, 5], "gener": 4, "vector": 4, "unigram": 4, "bigram": 4, "word2vec": 4, "np": [4, 5], "ndarrai": 4, "gensim": 4, "king": 4, "queen": 4, "man": 4, "vector_s": 4, "100": 4, "min_count": 4, "epoch": 4, "unknown_token": 4, "shape": 4, "word2vec_model": 4, "directori": 4, "nativ": 4, "sentenc": 4, "300": 4, "window": 4, "16": [4, 5], "corpu": 4, "librari": 4, "addit": 4, "can": 4, "via": 4, "machin": 4, "learn": 4, "wv": 4, "0123": 4, "0456": 4, "0789": 4, "nli_util": 5, "data_arg": 5, "model_arg": 5, "dataset": 5, "datatrainingargu": 5, "relat": 5, "modelargu": 5, "datasetdict": 5, "nli_finetun": 5, "task_nam": 5, "mnli": 5, "model_name_or_path": 5, "bert": 5, "uncas": 5, "raw_dataset": 5, "raw": 5, "pretrainedtoken": 5, "autotoken": 5, "from_pretrain": 5, "tokenized_dataset": 5, "metric": 5, "is_regress": 5, "regress": 5, "glue": 5, "evalpredict": 5, "compute_metr": 5, "pred": 5, "label": 5, "eval_pr": 5, "label_id": 5, "nli_train": 5, "trainer": 5, "training_arg": 5, "train_dataset": 5, "eval_dataset": 5, "data_col": 5, "hug": 5, "face": 5, "automodelforsequenceclassif": 5, "trainingargu": 5, "collat": 5, "orchestr": 5, "prepar": 5, "cache_dir": 5, "cach": 5, "train_fil": 5, "validation_fil": 5, "output_dir": 5, "do_train": 5, "do_ev": 5, "num_train_epoch": 5, "learning_r": 5, "2e": 5, "weight_decai": 5, "per_device_train_batch_s": 5, "per_device_eval_batch_s": 5, "report_to": 5, "helper": 8, "provided_env": 8, "environ": 8, "auto": 8, "detect": 8, "databrick": 8, "workspac": 8, "dev": 8, "stg": 8, "prod": 8, "cannot": 8}, "objects": {"centralized_nlp_package.common_utils": [[1, 0, 0, "-", "date_utils"], [1, 0, 0, "-", "file_utils"], [1, 0, 0, "-", "string_utils"]], "centralized_nlp_package.common_utils.date_utils": [[1, 1, 1, "", "format_date"], [1, 1, 1, "", "get_date_range"]], "centralized_nlp_package.common_utils.file_utils": [[1, 1, 1, "", "load_content_from_txt"]], "centralized_nlp_package.common_utils.string_utils": [[1, 1, 1, "", "format_string_template"], [1, 1, 1, "", "query_constructor"]], "centralized_nlp_package.data_access": [[2, 0, 0, "-", "snowflake_utils"]], "centralized_nlp_package.data_access.snowflake_utils": [[2, 1, 1, "", "execute_truncate_or_merge_query"], [2, 1, 1, "", "get_snowflake_connection_options"], [2, 1, 1, "", "read_from_snowflake"], [2, 1, 1, "", "retrieve_snowflake_private_key"], [2, 1, 1, "", "singleton"], [2, 1, 1, "", "with_spark_session"], [2, 1, 1, "", "write_dataframe_to_snowflake"]], "centralized_nlp_package.data_processing": [[3, 0, 0, "-", "dask_utils"], [3, 0, 0, "-", "dataframe_utils"], [3, 0, 0, "-", "spark_utils"]], "centralized_nlp_package.data_processing.dask_utils": [[3, 1, 1, "", "dask_compute_with_progress"], [3, 1, 1, "", "initialize_dask_client"]], "centralized_nlp_package.data_processing.dataframe_utils": [[3, 1, 1, "", "check_pd_dataframe_for_records"], [3, 1, 1, "", "concatenate_and_reset_index"], [3, 1, 1, "", "df_apply_transformations"], [3, 1, 1, "", "df_remove_rows_with_keywords"], [3, 1, 1, "", "save_report"]], "centralized_nlp_package.data_processing.spark_utils": [[3, 1, 1, "", "check_spark_dataframe_for_records"], [3, 1, 1, "", "convert_columns_to_timestamp"], [3, 1, 1, "", "create_spark_udf"], [3, 1, 1, "", "define_structure"], [3, 1, 1, "", "equivalent_type"], [3, 1, 1, "", "get_default_dtype_mapping"], [3, 1, 1, "", "initialize_spark_session"], [3, 1, 1, "", "keyword_to_datatype"], [3, 1, 1, "", "pandas_to_spark"], [3, 1, 1, "", "sparkdf_apply_transformations"]], "centralized_nlp_package.embedding": [[4, 0, 0, "-", "embedding_utils"], [4, 0, 0, "-", "word2vec_model"]], "centralized_nlp_package.embedding.embedding_utils": [[4, 1, 1, "", "average_token_embeddings"]], "centralized_nlp_package.embedding.word2vec_model": [[4, 1, 1, "", "save_word2vec_model"], [4, 1, 1, "", "train_word2vec_model"]], "centralized_nlp_package.nli_utils": [[5, 0, 0, "-", "data"], [5, 0, 0, "-", "metrics"], [5, 0, 0, "-", "nli_trainer"], [5, 0, 0, "-", "run_glue"]], "centralized_nlp_package.nli_utils.data": [[5, 1, 1, "", "prepare_datasets"], [5, 1, 1, "", "preprocess_datasets"]], "centralized_nlp_package.nli_utils.metrics": [[5, 1, 1, "", "get_compute_metrics"]], "centralized_nlp_package.nli_utils.nli_trainer": [[5, 1, 1, "", "evaluate"], [5, 1, 1, "", "initialize_trainer"], [5, 1, 1, "", "predict"], [5, 1, 1, "", "setup_logging"], [5, 1, 1, "", "train"]], "centralized_nlp_package.nli_utils.run_glue": [[5, 1, 1, "", "main"], [5, 1, 1, "", "run_glue"]], "centralized_nlp_package.utils": [[8, 0, 0, "-", "helper"]], "centralized_nlp_package.utils.helper": [[8, 1, 1, "", "determine_environment"]]}, "objtypes": {"0": "py:module", "1": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "central": 0, "nlp": 0, "packag": 0, "": 0, "document": 0, "content": 0, "indic": 0, "tabl": 0, "common": 1, "util": [1, 5, 8], "data": [2, 3], "access": 2, "process": [3, 7], "embed": 4, "nli": 5, "preprocess": 6, "text": 7}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Welcome to Centralized NLP Package\u2019s documentation!": [[0, "welcome-to-centralized-nlp-package-s-documentation"]], "Contents:": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "Common Utils": [[1, "module-centralized_nlp_package.common_utils.date_utils"]], "Data Access": [[2, "module-centralized_nlp_package.data_access.snowflake_utils"]], "Data Processing": [[3, "module-centralized_nlp_package.data_processing.dataframe_utils"]], "Embedding": [[4, "module-centralized_nlp_package.embedding.embedding_utils"]], "NLI utilities": [[5, "module-centralized_nlp_package.nli_utils.data"]], "Preprocessing": [[6, "preprocessing"]], "Text processing": [[7, "text-processing"]], "Utilities": [[8, "module-centralized_nlp_package.utils.helper"]]}, "indexentries": {"centralized_nlp_package.common_utils.date_utils": [[1, "module-centralized_nlp_package.common_utils.date_utils"]], "centralized_nlp_package.common_utils.file_utils": [[1, "module-centralized_nlp_package.common_utils.file_utils"]], "centralized_nlp_package.common_utils.string_utils": [[1, "module-centralized_nlp_package.common_utils.string_utils"]], "format_date() (in module centralized_nlp_package.common_utils.date_utils)": [[1, "centralized_nlp_package.common_utils.date_utils.format_date"]], "format_string_template() (in module centralized_nlp_package.common_utils.string_utils)": [[1, "centralized_nlp_package.common_utils.string_utils.format_string_template"]], "get_date_range() (in module centralized_nlp_package.common_utils.date_utils)": [[1, "centralized_nlp_package.common_utils.date_utils.get_date_range"]], "load_content_from_txt() (in module centralized_nlp_package.common_utils.file_utils)": [[1, "centralized_nlp_package.common_utils.file_utils.load_content_from_txt"]], "module": [[1, "module-centralized_nlp_package.common_utils.date_utils"], [1, "module-centralized_nlp_package.common_utils.file_utils"], [1, "module-centralized_nlp_package.common_utils.string_utils"], [2, "module-centralized_nlp_package.data_access.snowflake_utils"], [3, "module-centralized_nlp_package.data_processing.dask_utils"], [3, "module-centralized_nlp_package.data_processing.dataframe_utils"], [3, "module-centralized_nlp_package.data_processing.spark_utils"], [4, "module-centralized_nlp_package.embedding.embedding_utils"], [4, "module-centralized_nlp_package.embedding.word2vec_model"], [5, "module-centralized_nlp_package.nli_utils.data"], [5, "module-centralized_nlp_package.nli_utils.metrics"], [5, "module-centralized_nlp_package.nli_utils.nli_trainer"], [5, "module-centralized_nlp_package.nli_utils.run_glue"], [8, "module-centralized_nlp_package.utils.helper"]], "query_constructor() (in module centralized_nlp_package.common_utils.string_utils)": [[1, "centralized_nlp_package.common_utils.string_utils.query_constructor"]], "centralized_nlp_package.data_access.snowflake_utils": [[2, "module-centralized_nlp_package.data_access.snowflake_utils"]], "execute_truncate_or_merge_query() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.execute_truncate_or_merge_query"]], "get_snowflake_connection_options() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.get_snowflake_connection_options"]], "read_from_snowflake() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.read_from_snowflake"]], "retrieve_snowflake_private_key() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.retrieve_snowflake_private_key"]], "singleton() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.singleton"]], "with_spark_session() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.with_spark_session"]], "write_dataframe_to_snowflake() (in module centralized_nlp_package.data_access.snowflake_utils)": [[2, "centralized_nlp_package.data_access.snowflake_utils.write_dataframe_to_snowflake"]], "centralized_nlp_package.data_processing.dask_utils": [[3, "module-centralized_nlp_package.data_processing.dask_utils"]], "centralized_nlp_package.data_processing.dataframe_utils": [[3, "module-centralized_nlp_package.data_processing.dataframe_utils"]], "centralized_nlp_package.data_processing.spark_utils": [[3, "module-centralized_nlp_package.data_processing.spark_utils"]], "check_pd_dataframe_for_records() (in module centralized_nlp_package.data_processing.dataframe_utils)": [[3, "centralized_nlp_package.data_processing.dataframe_utils.check_pd_dataframe_for_records"]], "check_spark_dataframe_for_records() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.check_spark_dataframe_for_records"]], "concatenate_and_reset_index() (in module centralized_nlp_package.data_processing.dataframe_utils)": [[3, "centralized_nlp_package.data_processing.dataframe_utils.concatenate_and_reset_index"]], "convert_columns_to_timestamp() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.convert_columns_to_timestamp"]], "create_spark_udf() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.create_spark_udf"]], "dask_compute_with_progress() (in module centralized_nlp_package.data_processing.dask_utils)": [[3, "centralized_nlp_package.data_processing.dask_utils.dask_compute_with_progress"]], "define_structure() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.define_structure"]], "df_apply_transformations() (in module centralized_nlp_package.data_processing.dataframe_utils)": [[3, "centralized_nlp_package.data_processing.dataframe_utils.df_apply_transformations"]], "df_remove_rows_with_keywords() (in module centralized_nlp_package.data_processing.dataframe_utils)": [[3, "centralized_nlp_package.data_processing.dataframe_utils.df_remove_rows_with_keywords"]], "equivalent_type() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.equivalent_type"]], "get_default_dtype_mapping() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.get_default_dtype_mapping"]], "initialize_dask_client() (in module centralized_nlp_package.data_processing.dask_utils)": [[3, "centralized_nlp_package.data_processing.dask_utils.initialize_dask_client"]], "initialize_spark_session() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.initialize_spark_session"]], "keyword_to_datatype() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.keyword_to_datatype"]], "pandas_to_spark() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.pandas_to_spark"]], "save_report() (in module centralized_nlp_package.data_processing.dataframe_utils)": [[3, "centralized_nlp_package.data_processing.dataframe_utils.save_report"]], "sparkdf_apply_transformations() (in module centralized_nlp_package.data_processing.spark_utils)": [[3, "centralized_nlp_package.data_processing.spark_utils.sparkdf_apply_transformations"]], "average_token_embeddings() (in module centralized_nlp_package.embedding.embedding_utils)": [[4, "centralized_nlp_package.embedding.embedding_utils.average_token_embeddings"]], "centralized_nlp_package.embedding.embedding_utils": [[4, "module-centralized_nlp_package.embedding.embedding_utils"]], "centralized_nlp_package.embedding.word2vec_model": [[4, "module-centralized_nlp_package.embedding.word2vec_model"]], "save_word2vec_model() (in module centralized_nlp_package.embedding.word2vec_model)": [[4, "centralized_nlp_package.embedding.word2vec_model.save_word2vec_model"]], "train_word2vec_model() (in module centralized_nlp_package.embedding.word2vec_model)": [[4, "centralized_nlp_package.embedding.word2vec_model.train_word2vec_model"]], "centralized_nlp_package.nli_utils.data": [[5, "module-centralized_nlp_package.nli_utils.data"]], "centralized_nlp_package.nli_utils.metrics": [[5, "module-centralized_nlp_package.nli_utils.metrics"]], "centralized_nlp_package.nli_utils.nli_trainer": [[5, "module-centralized_nlp_package.nli_utils.nli_trainer"]], "centralized_nlp_package.nli_utils.run_glue": [[5, "module-centralized_nlp_package.nli_utils.run_glue"]], "evaluate() (in module centralized_nlp_package.nli_utils.nli_trainer)": [[5, "centralized_nlp_package.nli_utils.nli_trainer.evaluate"]], "get_compute_metrics() (in module centralized_nlp_package.nli_utils.metrics)": [[5, "centralized_nlp_package.nli_utils.metrics.get_compute_metrics"]], "initialize_trainer() (in module centralized_nlp_package.nli_utils.nli_trainer)": [[5, "centralized_nlp_package.nli_utils.nli_trainer.initialize_trainer"]], "main() (in module centralized_nlp_package.nli_utils.run_glue)": [[5, "centralized_nlp_package.nli_utils.run_glue.main"]], "predict() (in module centralized_nlp_package.nli_utils.nli_trainer)": [[5, "centralized_nlp_package.nli_utils.nli_trainer.predict"]], "prepare_datasets() (in module centralized_nlp_package.nli_utils.data)": [[5, "centralized_nlp_package.nli_utils.data.prepare_datasets"]], "preprocess_datasets() (in module centralized_nlp_package.nli_utils.data)": [[5, "centralized_nlp_package.nli_utils.data.preprocess_datasets"]], "run_glue() (in module centralized_nlp_package.nli_utils.run_glue)": [[5, "centralized_nlp_package.nli_utils.run_glue.run_glue"]], "setup_logging() (in module centralized_nlp_package.nli_utils.nli_trainer)": [[5, "centralized_nlp_package.nli_utils.nli_trainer.setup_logging"]], "train() (in module centralized_nlp_package.nli_utils.nli_trainer)": [[5, "centralized_nlp_package.nli_utils.nli_trainer.train"]], "centralized_nlp_package.utils.helper": [[8, "module-centralized_nlp_package.utils.helper"]], "determine_environment() (in module centralized_nlp_package.utils.helper)": [[8, "centralized_nlp_package.utils.helper.determine_environment"]]}})