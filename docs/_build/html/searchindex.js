Search.setIndex({"docnames": ["index", "source/data_access", "source/embedding", "source/preprocessing", "source/text_processing", "source/utils"], "filenames": ["index.rst", "source/data_access.rst", "source/embedding.rst", "source/preprocessing.rst", "source/text_processing.rst", "source/utils.rst"], "titles": ["Welcome to Centralized NLP Package\u2019s documentation!", "Data Access", "Embedding", "Preprocessing", "Text processing", "Utilities"], "terms": {"data": [0, 4, 5], "access": 0, "execute_snowflake_query_spark": [0, 1], "execute_truncate_or_merge_queri": [0, 1], "get_snowflake_connection_opt": [0, 1], "retrieve_snowflake_private_kei": [0, 1], "singleton": [0, 1], "with_spark_sess": [0, 1], "write_dataframe_to_snowflak": [0, 1], "dask_compute_with_progress": [0, 1], "initialize_dask_cli": [0, 1], "embed": 0, "average_token_embed": [0, 2], "save_word2vec_model": [0, 2], "train_word2vec_model": [0, 2], "preprocess": 0, "clean_text": [0, 3], "initialize_spaci": [0, 3], "preprocess_text": [0, 3], "preprocess_text_list": [0, 3], "remove_unwanted_phrases_and_valid": [0, 3], "tokenize_and_lemmatize_text": [0, 3], "tokenize_matched_word": [0, 3], "text": [0, 3], "process": [0, 1, 3, 5], "combine_sentiment_scor": [0, 4], "expand_contract": [0, 4], "generate_ngram": [0, 4], "load_content_from_txt": [0, 4], "load_set_from_txt": [0, 4], "load_syllable_count": [0, 4], "tokenize_text": [0, 4], "validate_and_format_text": [0, 4], "util": 0, "df_apply_transform": [0, 5], "df_remove_rows_with_keyword": [0, 5], "format_d": [0, 5], "format_string_templ": [0, 5], "get_date_rang": [0, 5], "load_fil": [0, 5], "query_constructor": [0, 5], "index": 0, "modul": 0, "search": 0, "page": 0, "centralized_nlp_packag": [1, 2, 3, 4, 5], "data_access": 1, "snowflake_util": 1, "queri": [1, 5], "sourc": [1, 2, 3, 4, 5], "execut": 1, "sql": [1, 5], "snowflak": 1, "return": [1, 2, 3, 4, 5], "result": 1, "spark": 1, "datafram": [1, 5], "paramet": [1, 2, 3, 4, 5], "str": [1, 2, 3, 4, 5], "The": [1, 2, 3, 4, 5], "type": [1, 2, 3, 4, 5], "rais": [1, 4, 5], "except": [1, 5], "If": [1, 4, 5], "i": [1, 3, 4, 5], "an": [1, 2, 4, 5], "error": [1, 4], "exampl": [1, 2, 3, 4, 5], "df": [1, 5], "select": [1, 5], "from": [1, 2, 4, 5], "my_tabl": 1, "truncat": 1, "merg": 1, "A": [1, 2, 4, 5], "confirm": 1, "messag": 1, "indic": 1, "complet": 1, "oper": 1, "tabl": 1, "construct": [1, 5], "dictionari": [1, 4], "connect": 1, "option": [1, 2, 3, 4, 5], "thi": [1, 2, 3, 4], "includ": 1, "account": 1, "url": 1, "user": [1, 5], "credenti": 1, "privat": 1, "kei": [1, 4, 5], "databas": 1, "schema": 1, "timezon": 1, "role": 1, "contain": [1, 4, 5], "dict": [1, 4], "snowflake_opt": 1, "retriev": 1, "azur": 1, "vault": 1, "akv": 1, "function": [1, 2, 5], "fetch": 1, "encrypt": 1, "password": 1, "decrypt": 1, "format": [1, 2, 4, 5], "authent": 1, "pem": 1, "suitabl": 1, "private_kei": 1, "cl": 1, "decor": 1, "make": 1, "class": 1, "ensur": [1, 2, 4], "onli": 1, "one": 1, "instanc": 1, "exist": [1, 2, 5], "func": [1, 5], "session": 1, "initi": [1, 2, 3, 4], "befor": 1, "table_nam": 1, "mode": 1, "append": 1, "write": 1, "specifi": [1, 2, 5], "target": 1, "name": [1, 5], "behavior": 1, "alreadi": 1, "ar": [1, 2, 4], "overwrit": 1, "ignor": 1, "default": [1, 2, 4, 5], "none": [1, 2, 3, 4], "target_t": 1, "dask_util": 1, "dask_datafram": 1, "use_progress": 1, "true": [1, 4], "comput": 1, "dask": 1, "displai": 1, "progress": 1, "bar": 1, "ani": [1, 2, 5], "bool": [1, 2, 4], "whether": [1, 2], "dure": [1, 5], "e": [1, 2, 5], "g": [1, 2, 5], "panda": 1, "import": [1, 2, 5], "dd": [1, 5], "read_csv": 1, "csv": 1, "computed_df": 1, "print": [1, 2, 3, 4, 5], "head": 1, "column1": 1, "column2": 1, "0": [1, 2, 3, 4, 5], "1": [1, 2, 5], "4": 1, "2": [1, 3, 4, 5], "5": [1, 2, 4], "3": [1, 3, 4], "6": 1, "n_worker": 1, "threads_per_work": 1, "client": 1, "number": [1, 3, 4, 5], "worker": 1, "thread": 1, "per": 1, "int": [1, 3, 4, 5], "distribut": 1, "object": [1, 5], "0x": 1, "embedding_util": 2, "token": [2, 3, 4], "model": [2, 3], "gener": [2, 4], "list": [2, 3, 4, 5], "averag": [2, 5], "vector": 2, "unigram": 2, "bigram": 2, "word2vec": 2, "train": 2, "np": 2, "ndarrai": 2, "gensim": 2, "king": 2, "queen": 2, "man": 2, "vector_s": 2, "100": 2, "min_count": 2, "epoch": 2, "10": [2, 5], "unknown_token": 2, "shape": 2, "word2vec_model": 2, "path": [2, 4, 5], "save": 2, "file": [2, 4, 5], "directori": 2, "": [2, 4, 5], "nativ": 2, "sentenc": [2, 3], "hello": [2, 3, 4, 5], "world": [2, 4], "fals": 2, "kwarg": [2, 5], "provid": [2, 5], "corpu": 2, "us": [2, 5], "either": 2, "configur": [2, 3], "librari": 2, "addit": 2, "can": [2, 3, 4], "via": 2, "keyword": [2, 5], "argument": [2, 5], "machin": 2, "learn": 2, "window": 2, "wv": 2, "arrai": 2, "0123": 2, "0456": 2, "0789": 2, "dtype": 2, "float32": 2, "text_preprocess": 3, "clean": 3, "input": [3, 4], "expand": [3, 4], "contract": [3, 4], "remov": [3, 5], "unwant": 3, "charact": 3, "normal": 3, "space": 3, "t": [3, 4], "go": [3, 4, 5], "parti": 3, "cannot": [3, 4], "spaci": [3, 4], "custom": 3, "set": [3, 4, 5], "languag": [3, 4], "nlp": [3, 4], "doc": 3, "sampl": [3, 4], "text_input": [3, 4], "valid": [3, 4], "union": [3, 4, 5], "word": [3, 4], "count": [3, 4], "tupl": [3, 4, 5], "cleaned_text": 3, "believ": 3, "text_list": 3, "each": [3, 4, 5], "love": [3, 4], "product": [3, 5], "hi": 3, "tokens_list": 3, "phrase": 3, "its": 3, "content": [3, 4, 5], "doesn": 3, "meet": 3, "criteria": 3, "lemmat": [3, 4], "document": 3, "exclud": [3, 4], "stop": [3, 4], "punctuat": 3, "filter": [3, 4, 5], "am": [3, 4], "new": [3, 4, 5], "featur": [3, 4], "match": [3, 5], "priorit": 3, "proper": 3, "noun": 3, "capit": 3, "john": 3, "york": 3, "text_process": 4, "text_util": 4, "positive_count": 4, "negative_count": 4, "combin": 4, "two": 4, "sentiment": 4, "score": 4, "singl": 4, "posit": 4, "neg": 4, "both": 4, "zero": 4, "float": 4, "25": 4, "base": [4, 5], "contraction_map": 4, "m": 4, "input_list": 4, "n": 4, "gram": 4, "yield": 4, "iter": 4, "over": 4, "code": 4, "file_path": [4, 5], "read": 4, "entir": 4, "given": [4, 5], "filesnotloadedexcept": [4, 5], "found": [4, 5], "txt": 4, "is_low": 4, "line": 4, "convert": 4, "lowercas": 4, "word_set": 4, "positive_word": 4, "happi": 4, "joy": 4, "delight": 4, "syllabl": 4, "where": [4, 5], "valu": 4, "ha": 4, "invalid": [4, 5], "syllable_count": 4, "beauti": 4, "spacy_token": 4, "perform": 4, "load": [4, 5], "en_core_web_sm": 4, "non": 4, "empti": 4, "string": [4, 5], "join": 4, "them": 4, "strip": 4, "els": 4, "helper": 5, "transform": 5, "appli": 5, "should": 5, "new_column": 5, "column": 5, "creat": 5, "columns_to_us": 5, "callabl": 5, "pd": 5, "valueerror": 5, "re": 5, "occur": 5, "after": 5, "log": 5, "def": 5, "concat_column": 5, "b": 5, "f": 5, "_": 5, "col1": 5, "col2": 5, "c": 5, "d": 5, "col3": 5, "lambda": 5, "row": 5, "transformed_df": 5, "a_c": 5, "b_d": 5, "column_nam": 5, "check": 5, "out": 5, "comment": 5, "good": 5, "bad": 5, "servic": 5, "experi": 5, "filtered_df": 5, "date": 5, "datetim": 5, "yyyi": 5, "mm": 5, "2023": 5, "9": 5, "15": 5, "09": 5, "templat": 5, "replac": 5, "placehold": 5, "form": 5, "variabl": 5, "doe": 5, "have": 5, "correspond": 5, "todai": 5, "dai": 5, "alic": 5, "mondai": 5, "years_back": 5, "months_back": 5, "calcul": 5, "rang": 5, "current": 5, "minu": 5, "year": 5, "month": 5, "back": 5, "start": 5, "end": 5, "start_dat": 5, "end_dat": 5, "2022": 5, "08": 5, "01": 5, "extern": 5, "get_us": 5, "query_input": 5, "o": 5, "pathlik": 5, "itself": 5, "substitut": 5, "do": 5, "signup_d": 5, "AND": 5, "12": 5, "31": 5}, "objects": {"centralized_nlp_package.data_access": [[1, 0, 0, "-", "dask_utils"], [1, 0, 0, "-", "snowflake_utils"]], "centralized_nlp_package.data_access.dask_utils": [[1, 1, 1, "", "dask_compute_with_progress"], [1, 1, 1, "", "initialize_dask_client"]], "centralized_nlp_package.data_access.snowflake_utils": [[1, 1, 1, "", "execute_snowflake_query_spark"], [1, 1, 1, "", "execute_truncate_or_merge_query"], [1, 1, 1, "", "get_snowflake_connection_options"], [1, 1, 1, "", "retrieve_snowflake_private_key"], [1, 1, 1, "", "singleton"], [1, 1, 1, "", "with_spark_session"], [1, 1, 1, "", "write_dataframe_to_snowflake"]], "centralized_nlp_package.embedding": [[2, 0, 0, "-", "embedding_utils"], [2, 0, 0, "-", "word2vec_model"]], "centralized_nlp_package.embedding.embedding_utils": [[2, 1, 1, "", "average_token_embeddings"]], "centralized_nlp_package.embedding.word2vec_model": [[2, 1, 1, "", "save_word2vec_model"], [2, 1, 1, "", "train_word2vec_model"]], "centralized_nlp_package.preprocessing": [[3, 0, 0, "-", "text_preprocessing"]], "centralized_nlp_package.preprocessing.text_preprocessing": [[3, 1, 1, "", "clean_text"], [3, 1, 1, "", "initialize_spacy"], [3, 1, 1, "", "preprocess_text"], [3, 1, 1, "", "preprocess_text_list"], [3, 1, 1, "", "remove_unwanted_phrases_and_validate"], [3, 1, 1, "", "tokenize_and_lemmatize_text"], [3, 1, 1, "", "tokenize_matched_words"]], "centralized_nlp_package.text_processing": [[4, 0, 0, "-", "text_utils"]], "centralized_nlp_package.text_processing.text_utils": [[4, 1, 1, "", "combine_sentiment_scores"], [4, 1, 1, "", "expand_contractions"], [4, 1, 1, "", "generate_ngrams"], [4, 1, 1, "", "load_content_from_txt"], [4, 1, 1, "", "load_set_from_txt"], [4, 1, 1, "", "load_syllable_counts"], [4, 1, 1, "", "tokenize_text"], [4, 1, 1, "", "validate_and_format_text"]], "centralized_nlp_package.utils": [[5, 0, 0, "-", "helpers"]], "centralized_nlp_package.utils.helpers": [[5, 1, 1, "", "df_apply_transformations"], [5, 1, 1, "", "df_remove_rows_with_keywords"], [5, 1, 1, "", "format_date"], [5, 1, 1, "", "format_string_template"], [5, 1, 1, "", "get_date_range"], [5, 1, 1, "", "load_file"], [5, 1, 1, "", "query_constructor"]]}, "objtypes": {"0": "py:module", "1": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"]}, "titleterms": {"welcom": 0, "central": 0, "nlp": 0, "packag": 0, "": 0, "document": 0, "content": 0, "indic": 0, "tabl": 0, "data": 1, "access": 1, "embed": 2, "preprocess": 3, "text": 4, "process": 4, "util": 5}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Welcome to Centralized NLP Package\u2019s documentation!": [[0, "welcome-to-centralized-nlp-package-s-documentation"]], "Contents:": [[0, null]], "Indices and tables": [[0, "indices-and-tables"]], "Data Access": [[1, "module-centralized_nlp_package.data_access.snowflake_utils"]], "Embedding": [[2, "module-centralized_nlp_package.embedding.embedding_utils"]], "Preprocessing": [[3, "module-centralized_nlp_package.preprocessing.text_preprocessing"]], "Text processing": [[4, "module-centralized_nlp_package.text_processing.text_utils"]], "Utilities": [[5, "module-centralized_nlp_package.utils.helpers"]]}, "indexentries": {"centralized_nlp_package.data_access.dask_utils": [[1, "module-centralized_nlp_package.data_access.dask_utils"]], "centralized_nlp_package.data_access.snowflake_utils": [[1, "module-centralized_nlp_package.data_access.snowflake_utils"]], "dask_compute_with_progress() (in module centralized_nlp_package.data_access.dask_utils)": [[1, "centralized_nlp_package.data_access.dask_utils.dask_compute_with_progress"]], "execute_snowflake_query_spark() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.execute_snowflake_query_spark"]], "execute_truncate_or_merge_query() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.execute_truncate_or_merge_query"]], "get_snowflake_connection_options() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.get_snowflake_connection_options"]], "initialize_dask_client() (in module centralized_nlp_package.data_access.dask_utils)": [[1, "centralized_nlp_package.data_access.dask_utils.initialize_dask_client"]], "module": [[1, "module-centralized_nlp_package.data_access.dask_utils"], [1, "module-centralized_nlp_package.data_access.snowflake_utils"], [2, "module-centralized_nlp_package.embedding.embedding_utils"], [2, "module-centralized_nlp_package.embedding.word2vec_model"], [3, "module-centralized_nlp_package.preprocessing.text_preprocessing"], [4, "module-centralized_nlp_package.text_processing.text_utils"], [5, "module-centralized_nlp_package.utils.helpers"]], "retrieve_snowflake_private_key() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.retrieve_snowflake_private_key"]], "singleton() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.singleton"]], "with_spark_session() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.with_spark_session"]], "write_dataframe_to_snowflake() (in module centralized_nlp_package.data_access.snowflake_utils)": [[1, "centralized_nlp_package.data_access.snowflake_utils.write_dataframe_to_snowflake"]], "average_token_embeddings() (in module centralized_nlp_package.embedding.embedding_utils)": [[2, "centralized_nlp_package.embedding.embedding_utils.average_token_embeddings"]], "centralized_nlp_package.embedding.embedding_utils": [[2, "module-centralized_nlp_package.embedding.embedding_utils"]], "centralized_nlp_package.embedding.word2vec_model": [[2, "module-centralized_nlp_package.embedding.word2vec_model"]], "save_word2vec_model() (in module centralized_nlp_package.embedding.word2vec_model)": [[2, "centralized_nlp_package.embedding.word2vec_model.save_word2vec_model"]], "train_word2vec_model() (in module centralized_nlp_package.embedding.word2vec_model)": [[2, "centralized_nlp_package.embedding.word2vec_model.train_word2vec_model"]], "centralized_nlp_package.preprocessing.text_preprocessing": [[3, "module-centralized_nlp_package.preprocessing.text_preprocessing"]], "clean_text() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.clean_text"]], "initialize_spacy() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.initialize_spacy"]], "preprocess_text() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.preprocess_text"]], "preprocess_text_list() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.preprocess_text_list"]], "remove_unwanted_phrases_and_validate() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.remove_unwanted_phrases_and_validate"]], "tokenize_and_lemmatize_text() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.tokenize_and_lemmatize_text"]], "tokenize_matched_words() (in module centralized_nlp_package.preprocessing.text_preprocessing)": [[3, "centralized_nlp_package.preprocessing.text_preprocessing.tokenize_matched_words"]], "centralized_nlp_package.text_processing.text_utils": [[4, "module-centralized_nlp_package.text_processing.text_utils"]], "combine_sentiment_scores() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.combine_sentiment_scores"]], "expand_contractions() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.expand_contractions"]], "generate_ngrams() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.generate_ngrams"]], "load_content_from_txt() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.load_content_from_txt"]], "load_set_from_txt() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.load_set_from_txt"]], "load_syllable_counts() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.load_syllable_counts"]], "tokenize_text() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.tokenize_text"]], "validate_and_format_text() (in module centralized_nlp_package.text_processing.text_utils)": [[4, "centralized_nlp_package.text_processing.text_utils.validate_and_format_text"]], "centralized_nlp_package.utils.helpers": [[5, "module-centralized_nlp_package.utils.helpers"]], "df_apply_transformations() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.df_apply_transformations"]], "df_remove_rows_with_keywords() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.df_remove_rows_with_keywords"]], "format_date() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.format_date"]], "format_string_template() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.format_string_template"]], "get_date_range() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.get_date_range"]], "load_file() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.load_file"]], "query_constructor() (in module centralized_nlp_package.utils.helpers)": [[5, "centralized_nlp_package.utils.helpers.query_constructor"]]}})